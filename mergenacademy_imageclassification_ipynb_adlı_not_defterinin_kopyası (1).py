# -*- coding: utf-8 -*-
"""MergenAcademy-ImageClassification.ipynb adlı not defterinin kopyası

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gfJROcdFxTt0RpIXkxmZdfJRdixGiHAj
"""

!pip install kaggle

import os
os.environ['KAGGLE_USERNAME'] = "makerb"
os.environ['KAGGLE_KEY'] = "4318c0f683ec26e3b29a0d98d28ce867"

!kaggle datasets download -d berkaykocaoglu/tr-sign-language

import zipfile
with zipfile.ZipFile('tr-sign-language.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/dataset')

# Commented out IPython magic to ensure Python compatibility.
# Import necessary libraries
import os
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, models
from torchvision.datasets import ImageFolder

import matplotlib.pyplot as plt
# %matplotlib inline

# Set the device (GPU or CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define data transforms
# 1. Resize the input images to 224x224 pixels
# 2. Convert the images to PyTorch tensors
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Define the base data directory where train and test subdirectories are located
data_dir = '/content/dataset/tr_signLanguage_dataset'

# Create the training and testing datasets with the specified data transformations
train_dataset = ImageFolder(os.path.join(data_dir, 'train'), transform=transform)
test_dataset = ImageFolder(os.path.join(data_dir, 'test'), transform=transform)

# Set the batch size for data loading
batch_size = 32

# Create data loaders for the training and testing datasets
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

# Define the number of sample images to display
num_samples = 4

# Create a data loader for displaying sample images
sample_loader = DataLoader(train_dataset, batch_size=num_samples, shuffle=True)
dataiter = iter(sample_loader)
images, labels = next(dataiter)

# Define class names
class_names = train_dataset.classes

# Plot the sample images
fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))
for i in range(num_samples):
    image = images[i].numpy().transpose((1, 2, 0))
    axes[i].imshow(image)
    axes[i].set_title(f'Class: {class_names[labels[i]]}')
    axes[i].axis('off')

plt.show()

# Define the model
model = models.resnet101(pretrained=True)
num_classes = len(train_dataset.classes)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model.to(device)

# Define the loss function
criterion = nn.CrossEntropyLoss()

# Define the optimizer (using Adam) with a specific learning rate
learning_rate = 0.0001
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training the model
num_epochs = 7

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    # Iterate over the training data with a progress bar
    for data in tqdm(train_loader, total=len(train_loader)):

        # Get input data and labels, move them to the device (CPU or GPU)
        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)

        # Compute the loss
        loss = criterion(outputs, labels)

        # Backpropagation
        loss.backward()

        # Update model parameters
        optimizer.step()

        running_loss += loss.item()

    # Calculate and print the average loss for the current epoch
    average_loss = running_loss / len(train_loader)
    print(f"Epoch {epoch + 1}, Loss: {average_loss:.4f}")

# Set the model to evaluation mode
model.eval()

# Initialize variables to track correct and total predictions
correct = 0
total = 0

# Use no gradient computation for testing
with torch.no_grad():
    for data in tqdm(test_loader, total=len(test_loader)):
        inputs, labels = data[0].to(device), data[1].to(device)
        outputs = model(inputs)

        # Get the predicted class for each image
        _, predicted = torch.max(outputs, 1)

        total += labels.size(0)
        correct += (predicted == labels).sum().item()

# Calculate and print the accuracy on the test set
accuracy = 100 * correct / total
print(f"Accuracy on the test set: {accuracy:.2f}%")
model

# Set the model to evaluation mode
model.eval()

# Define the number of sample images to display
num_samples = 5

# Create a data loader for displaying sample images
sample_loader = DataLoader(test_dataset, batch_size=num_samples, shuffle=True)
dataiter = iter(sample_loader)
images, labels = next(dataiter)

with torch.no_grad():
    # Move images to the device (CPU or GPU)
    images = images.to(device)

    # Make predictions on the selected images
    outputs = model(images)
    predicted_prob, predicted = torch.max(outputs, 1)
    class_probs = torch.softmax(outputs, dim=1)

# Define class names
class_names = train_dataset.classes

# Plot the selected images, their predictions, and class probabilities
fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))
for i in range(num_samples):
    image = images[i].cpu().numpy().transpose((1, 2, 0))
    axes[i].imshow(image)
    prediction_text = f'Prediction: {class_names[predicted[i]]} ({class_probs[i][predicted[i]]:.2f})'
    actual_text = f'Actual: {class_names[labels[i]]}'
    axes[i].set_title(f'{prediction_text}\n{actual_text}')
    axes[i].axis('off')

plt.show()